date: 2013-05-29
layout: post
title: "并行计算介绍（翻译）"
description: ""
category: "学习"
tags: [computing, parallel]
published: true

[原文](https://computing.llnl.gov/tutorials/parallel_comp/)

并行计算介绍
===========

## 摘要


## 概述

### 什么是并行计算？

- 传统软件是为了串行计算编写的：
	- 运行在一个一台单核计算机上
	- 问题被分割为一系列的指令
	- 指令一个接着一个执行
	- 同一时刻只能有一个指令执行
- 直觉上，并行计算是同时使用多个计算资源解决计算问题
	- 运行在多核环境下
	- 问题本分割为独立的可并行执行的单元
	- 每个单元的指令同时在不同的CPU上执行
- 计算资源可能是：
	- 一台多核计算机
	- 网络连接的任意数量的计算机
	- 上面两种的结合
- 计算的问题应该能够：
	- 可以分割为可以同时执行独立的片段	
	- 可以在任意时刻同时执行多个程序指令
	- 使用多计算机资源花费时间少于单个计算机资源

#### 宇宙是并行的

#### 并行计算的使用

- 科学和工程
- 工业和商业

### 为什么使用并行计算

- 主要原因
	- 节省时间和/或金钱
	- 解决大型的问题
	- 提供并行性
	- 使用非本地资源
	- 串行计算的限制
		- 传输速度
		- 微型化的限制
		- 商业限制
		- 现在的计算机架构依赖硬件层的并行提高性能
			- 多执行单元
			- 指令流水线
			- 多核
- 使用者
	- [Top500.org](http://top500.org/)

- 未来
	- 并行化是计算的未来
	- 现在已经是百亿亿次级


## 概念与术语

### 冯诺依曼体系结构

- 冯诺依曼在1945的论文中首次提出的概念
- 基本上所有计算机使用这种基本的设计
	- 包含四个主要组件
		- 内存
		- 控制单元
		- 逻辑算法单元
		- 输入/输出
	- 读写，随机访问
	- 控制单元从内存获取指令或数据，解码指令然后顺序协调执行
	- 逻辑算法单元执行基本的算法操作
	- 输入输出是人操作的接口
- 并行计算机仍然保留基本的设计，体系结构基础保持一样

### Flynn分类法

- SISD
	- 串行计算机
	- 单指令：一个时钟周期只有一个指令流
	- 单数据：一个时钟周期只有一个数据流作为输入
	- 确定性执行
	- 最老最通用的类型
	- 例子：老一代大型机，微型电脑和工作站；现代的PC。
- SIMD
	- 并行计算机
	- 单指令：所有的计算单元在同一时钟周期执行相同的指令
	- 多数据：每个处理单元操作不同的数据
	- 适合图像处理
	- 同步锁可判断执行
	- 两个类型：处理阵列和矢量流水线
	- 现代的计算机，一部分使用的GPU使用了SIMD技术
- MISD
	- 并行计算机
	- 多指令：多个处理单元通过独立的指令流操作数据
	- 单数据：单数据流提供多个处理单元
	- 实例很少
	- 可以想象的使用场景
		- 对一个信号流的多频率滤波
		- 对一条信息的使用多个密码算法
- MIMD
	- 并行计算机
	- 多指令：每个处理器可能执行不同的指令
	- 多数据：每个处理器可以处理不同的数据流
	- 执行可以是同步或异步，确定或非确定
	- 现在，最通用的是超级计算机
	- 例子：大部分超级计算机，“网格”，多核SMP计算机，多核PC
	- 许多MIMD架构包含SIMD执行子组件

### 通用的并行术语

- HPC：高性能计算，使用世界最大的计算机解决大型问题
- Node：节点
- CPU/Socket/Processor/Core: 
- Task:
- Pipelining:
- Shared Memory:
- Symmetric Multi-Processor(SMP):
- Distributed Memory:
- Communications:
- Synchronization:
- Granularity:
- Observed Speedup:
- Parallel Overhead:
- Massively Parallel:
- Embarrassingly Parallel:
- Scalability；


## 并行计算机内存架构

### 共享内存
- 总体特性
	- 共享内存并行计算机访问所有内存作为全局内存空间
	- 多处理器可以独立操作但是共享相同的内存资源
	- 一个处理器的改内存操作可以被其他所有处理器可见
	- 共享内存机器可分为：
		- UMA：SMP，访问内存的时间相等
		- NUMA：访问内存时间不一致
- 优点
	- 全局地址空间对编程友好
	- task之间数据共享速度一致
- 缺点
	- 缺少扩展性，内存，CPUs
	- 程序员负责同步设计保证正确访问全局内存
	- 设计代价随着处理器数量的增加而加大

### 分布式内存
- 总体特性
	- 需要一个通信网络连接处理器内部内存
	- 处理器有本地内存，没有全局地址空间概念
	- 本地内存的改变对其他处理器内存无影响
	- 当处理器需要访问另一个处理器的数据时由程序员决定如何数据通信
	- fabric使用广泛，可以看作网卡
- 优点
	- 内存随着处理器数量的增加是可扩展的
	- 处理器可以迅速的访问自己的内存接口，不需要处理冲突和缓存一致性
	- 花费可控制
- 缺点
	- 程序员负责处理器间数据通信的细节
	- 从全局内存映射存在的数据结构到这种内存结构比较困难
	- 非一致的内存访问时间

### 混合的分布式-共享内存架构

- 最新最快的计算机同时使用分布式和共享的内存架构
- 共享内存的单元可以是缓存一致性的SMP机器或GPU
- 分布式内存的单元可以是网络连接的多个SMP/GPU机器
- 在可预测的未来，这种架构将继续在高端计算领域流行发展
- 优缺点同两种结构一样



## 并行计算模型

### 概述
- 有多种并行编程模型
	- 共享内存（不使用线程）
	- 线程
	- 分布式内存/消息传递
	- 数据并行
	- 混合
	- 单程序多数据（SPMD）
	- 多程序多数据（MPMD）
- 并行编程模型作为一个硬件和内存架构之上的抽象存在
- 任何一种模型可以实现在任一种硬件上。
- 使用哪种模型？
	- 没有最好只有更合适

### 共享内存模型（不使用线程）
- Tasks共享同一个公共的地址空间，可以异步读写
- 多种机制，如锁、信号量，可以用来控制对共享内存的访问
- 程序远的观点看没有数据拥有者的概念，程序开发简化了
- 缺点是管理本地数据的困难
	- 保持处理器的本地数据节省内存访问，缓存刷新，但是总线通信发生在多处理器使用相同的数据时
	- 不幸的是，普通用户很难使用和理解控制本地数据
- 实现
	- 本地编译器 and/or 硬件翻译 用户程序变量到实际的全局内存地址，在实际的单个SMP机器上，这个是直接的
	- 在分布式共享内存机器中，物理内存是分布在网络机器上的，通过软硬件转换成全局的

### 线程模型
- 是共享内存模型中的一种
- 一个单一的进程可以有多个并行的执行路径
- 实现
	- 从编程角度看，线程实现通常包含：
		- 并行源代码内部的可以调用的库
		- 编译器指令，可以嵌入在并行或串行的源代码中的
	- 两个不同的实现
		- POSIX Threads
			- 基于库，要求并行编程
			- 只支持C语言
			- 一般作为Pthreads提到
			- 许多设备商提供Pthreads支持
			- 明确的并行化，需要程序员掌握细节
		- OpenMP
			- 基于编译器指令，可以串行编程
			- 由一组硬件厂商共同定义
			- 可移植/多平台
			- 可以使用C/C++ 和Fortran实现
			- 使用简单，提供增量并行化
		- 微软有自己的线程实现，与UNIX POSIX和OpenMP无关

### 分布式内存/消息传递模型

- 模型特点
	- 使用本地内存进行计算的task集合。多个task可能在同一台物理机器上也可能在任意数量的机器上
	- 通过发送、接收消息的方式进行交换数据来通信
	- 数据传输需要各自处理器的协同操作
- 实现
	- 从编程角度看，消息传递实现通常由一个子程序库实现。源代码中调用子程序的库，程序员负责判断所有的并行
	- 历史上，消息传递库众多，使消息程序员编写可执行程序困难。
	- 1992年MPI论坛成立
	- 1994年发布MPI part1，1996年发布MPI part2
	- MPI实现在的消息传递的默认工业标准

### 数据并行模型
- 模型特点
	- 主要工具集中在对一个数据集的操作，数据集通常组织为一个通用的结构
	- task集合工作在共同的数据结构，可是，工作在数据结构中不同的部分
	- task在各自的分区执行相同的操作
	- 共享内存架构，所有的task可以访问全局内存的数据结构；分布式内存结构中，数据结构分为chunks，放在每个task的本地内存中
- 实现
	- Fortran 90 和 95
	- HPF 高性能Fortran
	- 编译器指令
	- 模型的分布式内存实现时，要求编译器产生使用MPI调用的代码。所以的消息传递对程序员来说是不可见的。

### 混合模型
- 由不只一种编程模型组成
- 现在，通常的实现是，MPI和OpenMP结合
	- 线程执行密集的核心程序，使用本地的节点数据
	- 不同节点上的进程间通信使用MPI
- 混合模型可以使自己使用快速增长的通用硬件环境
- 另一个相似的例子是使用MPI和GPU编程
	- GPU执行密集型的核心程序，使用本地的节点数据
	- 不同节点上的进程间的通信使用MPI

### SPMD 和 MPMD

- SPMD
	- 高级的编程模型，可以构建在上述的模型之上
	- 所有的task同时执行相同的程序拷贝
	- 所以的tasks可能使用不同的数据
	- 通过必要的逻辑控制，task可以不必执行整个程序
- MPMD
	- 高级的编程模型，可以构建在上述的模型之上
	- task可以同时执行不同的程序
	- 可以使用不同的数据

## 设计并行计算程序
### 自动并行 vs 手动并行
- 并行化的编译器有两种不同的工作方式
	- 全自动
		- 编译器分析源代码识别出可并行化的机会
		- 分析包括影响并行化的因素和并行化是否会提高性能
		- 循环是自动化最常使用的目标
	- 程序员管理
		- 使用编译器指令或者可能的编译器标志，程序员明确告诉编译器如何并行化
		- 可能用在连接相同程序的自动并行化
- 自动并行化的注意事项
	- 可能产生错误的结果
	- 可能会降低性能
	- 比手动并行的灵活性小
	- 限制在代码的子集上
	- 如果存在抑制因素或代码太复杂，可能实际产生不了并行代码

### 理解问题和程序
- 首先判断问题是否可以被并行化
- 识别程序的热点
- 识别程序中的瓶颈
- 识别抑制因子，如数据依赖
- 调查其他可行的算法
- 利用第三方的优化软件进行优化

### 分割

- 并行的第一步是分割，把问题分割为独立的chunks
- 两种基本的分割方式
	- Domain Decomposition
		- 数据被分割
		- 分割数据的不同方式 1D，2D
	- Functional Decomposition
		- 生态系统模型
		- 信号处理模型
		- 气象模型

### 通信

- 谁需要通信
	- tasks间需要共享数据
- 考虑的因素
	- 通信开销
	- 延迟和带宽
	- 通信的可见性
	- 异步、同步通信
	- 通信范围
	- 通信效率
	- 开销和复杂性
### 同步
- Barrier
- Lock / semaphore
- Synchronous communication operations

### 数据依赖
- 定义
	- 依赖：当声明影响了程序的结果
	- 数据依赖：来自不同task的对相同存储位置的使用
- 例子
	- 循环和数据依赖
	- 循环独立数据依赖
- 处理数据依赖
	- 分布式内存架构：通信需要同比点
	- 共享内存结构：tasks间同步读写操作

### 负载均衡

- 最小化task空闲时间
- 最慢的task决定整体的性能
- 怎样实现？
	- 平均分割工作
	- 使用动态任务分配

### 粒度
- 计算/通信比
- 细粒度并行化
- 粗粒度并行化

### I/O
- I/O 操作是并行化的抑制因素
- 并行文件系统可用的有
	- GPFS
	- Lustre
	- PVFS/PVFS2
	- PanFS
	- HP SFS
- MPI中有I/O编程接口

### 并行编程的限制和花费
- Amdahl's Law
- 复杂性
- 可移植性
- 资源要求
- 可扩展性

### 性能分析和调试


## 并行实例

- 阵列处理
- 计算PI
- 简单热学分析
- 波形公式

## 引文及更多信息

